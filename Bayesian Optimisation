#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Tue Aug 13 05:20:06 2024

@author: leszekwierzchleyski
"""

""" This code performs Bayesian optimisation to tune the hyper-parameters for 
the Boosted Tree Model. Many Thanks to  Pralabh Saxena. This code is based in 
part on Pralabh's code 
https://www.comet.com/site/blog/hyperparameter-tuning-with-bayesian-optimization/"""

import xgboost as xg
from sklearn import model_selection
import pandas as pd
from skopt import BayesSearchCV
import warnings

warnings.simplefilter("ignore", UserWarning)

"""Many thanks to Guillem SD for this data set. To produce a fresh link please 
visit https://www.kaggle.com/datasets/guillemservera/precious-metals-data. 
Licence Link https://creativecommons.org/licenses/by-nc/4.0/."""


filepath = 'https://storage.googleapis.com/kagglesdsdata/datasets/3625760/8779871/individual_data/Palladium_data.csv?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20240813%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20240813T014323Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=2f8b68540ff1cf69701bccb607bca942302cfdb18d156201706bc6545f4f4cd5a0fbbe27b9e9c53e0549fbb5e543fed3e3cdb92f47de99cbeaf9ce24fc87267d9846bf4bb38fdf4bb853a5f287b71b9e3cf3fb170ad729511f589dd8e71218aef1ccffa0acb4c9f84c4adde5bf3ec91d5dc38953efd5e0b626decbab596828f19544e3c1c434a6318b19e40d517c90352ebdc42fe85925fb9f114ae0eb37b63aae68c0520033c090058c6889aea5c863b7a50d677d603ba167d14df41639195146b9c869aa6ac3e2055420abc03b89a209d44afa2a51d4940f9bbe1db84799de0046f0ed31a57c441b7b2e65298adc4bdf09c3ec2213dcf51f1dcf2003bb5116'
dataframe = pd.read_csv(filepath)
dataframe.drop(columns=["date"], inplace=True)



"""Prepare labels for training"""

future_list = []

for i in range(len(dataframe)-10):
    future = dataframe.iloc[:,3][i+1] - dataframe.iloc[:,3][i]
    future_list.append(future)

label_list = []
for i in future_list:
    if i >= 20:
        label = 1
    else:
        label = 0
    label_list.append(label)
label_list.append(0)
label_list.append(0)
label_list.append(0)
label_list.append(0)
label_list.append(0)
label_list.append(0)
label_list.append(0)
label_list.append(0)
label_list.append(0)
label_list.append(0)

"""Prepare data for Boosted Tree Model."""

y_train = pd.DataFrame({'Buy?': label_list})

print(dataframe.head())
x_train, x_test, y_train, y_test= model_selection.train_test_split(dataframe, y_train, test_size=0.2, random_state=1)
dtrain = xg.DMatrix(x_train, label=y_train, enable_categorical=True)

"""Build search spaces"""

param_space = {
 'learning_rate': (0.1, 1.0, 'log-uniform'),
 'max_depth': (1, 10),
 'gamma': (1e-9, 0.6, 'log-uniform'),
 'n_estimators': (50, 100),
 'degree': (1, 6),  
 'kernel': ['linear', 'rbf', 'poly']
}

"""Run Bayesian Optimiser"""

optimizer = BayesSearchCV(
   estimator=xg.XGBClassifier(n_jobs=1),
 search_spaces=param_space,
 scoring='accuracy',
 cv=5,
 n_iter=200,
)
optimizer.fit(x_train, y_train)
best_params = optimizer.best_params_
best_score = optimizer.best_score_
print(f"Best parameters: {best_params}")
print(f"Best accuracy score: {best_score}")
